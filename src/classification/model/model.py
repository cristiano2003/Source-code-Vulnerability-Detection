from .codebert import *
import pytorch_lightning as pl
from transformers import AutoTokenizer, AutoModel
import torch.nn as nn


class Model(pl.LightningModule):
    def __init__(self):
        super().__init__()
        codebert_model = AutoModel.from_pretrained("microsoft/codebert-base")
        self.model = CodeBERTForVulnDetection(codebert = codebert_model)
        self.loss = nn.BCEWithLogitsLoss(weight=torch.tensor([1.9, 0.68]))

    def forward(self, input_ids, attention_mask):
        return self.model(input_ids, attention_mask)

    def training_step(self, batch, batch_idx):
        input_ids = batch[0]
        attention_mask = batch[1]
        labels = batch[2]
        
        outputs = self(input_ids, attention_mask)
        loss = self.loss(outputs, labels)
        self.log('train_loss', loss)
        
        return loss

    def validation_step(self, batch, batch_idx):
        input_ids = batch[0]
        attention_mask = batch[1]
        labels = batch[2]
              
        outputs = self(input_ids, attention_mask)
        loss = self.loss(outputs, labels)
        self.log('val_loss', loss)
        
        return loss 

    def configure_optimizers(self):
    
        return torch.optim.AdamW(self.model.parameters(), lr=1e-5, weight_decay=0.05)